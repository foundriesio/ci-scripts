#!/usr/bin/python3
from concurrent.futures import ThreadPoolExecutor
import json
import os
import io
import pty
import sys
from tempfile import mkstemp
import requests
import tarfile
from shutil import rmtree
from typing import List

from helpers import (
    Progress,
    cmd,
    fio_dnsbase,
    generate_credential_tokens,
    load_extra_certs,
    require_env,
    require_secrets,
    secret,
    http_get,
    status,
)
from static_deltas import (
    Delta,
    generate_deltas,
    save_delta_stats,
    upload_delta_stats
)


class ProgressCb:
    def __init__(self, total_length: 0):
        self.total_length = total_length
        self.total_written = 0
        self.next_percent = 5

    def cb(self, written: int):
        self.total_written += written
        percent = round(self.total_written / self.total_length * 100)
        if percent >= self.next_percent:
            status("Downloaded %d%% " % self.next_percent, with_ts=True)
            self.next_percent += 5


def drain(progress: Progress, u, prog_cb: ProgressCb.cb, dst: str, tok_secret_name: str):
    r = http_get(u, headers={
        "OSF-TOKEN": secret(tok_secret_name),
        "Connection": "keep-alive",
        "Keep-Alive": "timeout=1200, max=1"  # keep connection alive for 1 request for 20m
    }, stream=True)
    last_pos = 0
    with io.BufferedReader(r.raw, buffer_size=1024 * 1024) as br:
        with tarfile.open(fileobj=br, mode="r|bz2") as tar_stream:
            for member in tar_stream:
                tar_stream.extract(member, dst)
                prog_cb(br.tell() - last_pos)
                last_pos = br.tell()
    status(f"Downloaded and extracted: {u}")
    progress.tick()


def _download_extract(progress: Progress, tarurls: set[str], dst: str, tok_secret_name: str):
    status("Downloading the following {} ostree repos into the single one -> {}ostree_repo\n\t{}"
           .format(len(tarurls), dst, "\n\t".join(tarurls)))
    total_length = 0
    for u in tarurls:
        r = requests.head(u, headers={"OSF-TOKEN": secret(tok_secret_name)}, allow_redirects=True)
        if r.status_code != 200:
            sys.exit('Unable to find %s: %d\n%s' % (u, r.status_code, r.text))
        total_length += int(r.headers["content-length"])

    cb = ProgressCb(total_length)

    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        for u in tarurls:
            futures.append(executor.submit(drain, progress, u, cb.cb, dst, tok_secret_name))
        for f in futures:
            f.result()


def pull_ostree_commit(factory: str, commit_hash: str, ostree_repo_dir: str, tok_secret_name: str,
                       base_url: str):
    auth_url = f"{base_url}/{factory}/v2/repos/lmp/download-urls"
    r = requests.post(auth_url, headers={"osf-token": secret(tok_secret_name)})
    r.raise_for_status()

    pull_base_url = r.json()[0]["download_url"]
    pull_token = r.json()[0]["access_token"]

    if not os.path.exists(os.path.join(ostree_repo_dir, "config")):
        cmd("ostree", "init", "--repo", ostree_repo_dir, "--mode", "archive")

    cmd("ostree", "remote", "add", "--force", "--repo", ostree_repo_dir,
        "--no-gpg-verify", "gcs", pull_base_url)

    def read_progress(fd):
        data = os.read(fd, 70)
        line = data.decode()
        start_indx = line.find("Receiving")
        if start_indx == -1:
            return "\n".encode("ascii")
        res = "|--" + line[start_indx:].rstrip()
        sys.stdout.buffer.flush()
        return res.replace('\xa0', "%").encode("ascii")

    pty.spawn(["ostree", "pull", "--repo", ostree_repo_dir, "--update-frequency=5000",
               f"--http-header=Authorization=Bearer {pull_token}", "gcs", commit_hash],
              read_progress)


def main(creds_zip_file: str, deltas: List[Delta], factory: str, tok_secret_name: str, out_dir: str):
    load_extra_certs()

    work = 3  # 1 for the fiopush + 2 for saving and uploading delta stats files
    downloads = set()  # a set of URLs to ostree repo archives to download from Jobserv
    pulls = set()  # a set of ostree commit hashes to pull from ostreehub (if no URL to archive)
    for d in deltas:
        (e, s) = (d.to[1], downloads) if d.to[1] else (d.to[0], pulls)
        if e not in s:
            work += 1
            s.add(e)
        for x in d.froms:
            (e, s) = (x[1], downloads) if x[1] else (x[0], pulls)
            if e not in s:
                work += 2  # 2 for the "from":  download | pull, and generate delta
                s.add(e)

    base = fio_dnsbase()
    ostree_url = f"https://api.{base}/ota/ostreehub"

    prog = Progress(work)
    if len(downloads) > 0:
        _download_extract(prog, downloads, "./", tok_secret_name)

    if len(pulls) > 0:
        status(f"Pulling: {pulls} -> ./ostree_repo")
        for commit in pulls:
            pull_ostree_commit(factory, commit, "./ostree_repo", tok_secret_name, ostree_url)
            prog.tick()

    delta_stats = generate_deltas(prog, deltas, "./ostree_repo")

    # update summary and generate a new type of delta indexes
    cmd("ostree", "summary", "-u", "--repo=./ostree_repo")

    # TODO: remove the following code that determines and prints a type of delta indexes been generated
    #  once we completely switch to the new indexes types. https://foundriesio.atlassian.net/browse/FFTK-1122
    if os.path.isdir("./ostree_repo/delta-indexes"):
        with open("./ostree_repo/config", "r") as f:
            config = f.readlines()
        for e in config:
            if e == "indexed-deltas=true\n":
                status("New type of delta indexes are generated and enabled in the repo config")
                break
    else:
        status("Old type of delta indexes are generated (in-summary type)")

    rmtree("./ostree_repo/objects")  # We just need to sync deltas
    os.remove("./ostree_repo/summary")  # summary is generated by the ostree server
    cmd("fiopush", "-summary", "-repo=./ostree_repo", "-creds", creds_zip_file)
    prog.tick()

    status(f"Saving delta statistics files to {out_dir}...")
    save_delta_stats(delta_stats, out_dir)
    prog.tick()

    upload_delta_stats(factory, delta_stats, tok_secret_name)
    prog.tick()


if __name__ == "__main__":
    require_env("FACTORY")
    require_secrets("osftok", "triggered-by", "deltas", "targets.sec", 'root.json', 'targets.pub')
    _, creds_tmp = mkstemp()
    generate_credential_tokens(creds_tmp)

    deltas: List[Delta] = []
    for d in json.loads(secret("deltas")):
        deltas.append(Delta(**d))

    factory = os.environ["FACTORY"]
    repo_parent = os.environ.get("OSTREE_REPO_ROOT", "/")
    os.chdir(repo_parent)
    main(creds_tmp, deltas, factory, "osftok", os.environ.get("ARCHIVE", "/archive"))
