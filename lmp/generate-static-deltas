#!/usr/bin/python3
from concurrent.futures import ThreadPoolExecutor, wait
import json
import os
from tempfile import TemporaryDirectory, mkstemp
from shutil import rmtree
from subprocess import Popen, PIPE
import sys
from typing import List, NamedTuple, Optional, Tuple

from helpers import (
    Progress,
    cmd,
    generate_credential_tokens,
    require_env,
    require_secrets,
    secret,
    secret_get,
    status,
)


class Delta(NamedTuple):
    to: Tuple[str, str]
    froms: List[Tuple[str, str]]


class ProgressCb:
    def __init__(self, total_length: 0):
        self.total_length = total_length
        self.total_written = 0
        self.next_percent = 5

    def cb(self, written: int):
        self.total_written += written
        percent = round(self.total_written / self.total_length * 100)
        if percent >= self.next_percent:
            status("Downloaded %d%% " % self.next_percent, with_ts=True)
            self.next_percent += 5


def drain(progress: Progress, response, prog_cb: ProgressCb, dst: str):
    p = Popen(["tar", "-xj"], cwd=dst, stdin=PIPE)
    for chunk in response.iter_content(chunk_size=1024 * 1024):
        if chunk:
            p.stdin.write(chunk)
            prog_cb(len(chunk))
    p.stdin.close()
    p.wait()
    progress.tick()


def _download_extract(progress: Progress, tarurls: List[str], dst: str):
    status(f"Downloading: {tarurls} -> {dst}")

    total_length = 0
    responses = []
    for u in tarurls:
        r = secret_get(u, "osftok", "OSF-TOKEN", stream=True)
        total_length += int(r.headers["content-length"])
        responses.append(r)

    cb = ProgressCb(total_length)

    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = []
        for r in responses:
            futures.append(executor.submit(drain, progress, r, cb.cb, dst))
        for f in futures:
            f.result()


def main(creds_zip_file: str, deltas: List[Delta]):
    work = 1  # 1 for the fiopush
    downloads = []
    for d in deltas:
        downloads.append(d.to[1])
        downloads.extend([x[1] for x in d.froms])
        # 1 for "to" download, 2 for the "from" download and static delta
        work += 1 + (2 * len(d.froms))

    prog = Progress(work)
    _download_extract(prog, downloads, "./")

    for d in deltas:
        for f in d.froms:
            sha, _ = f
            status("Generating delta", with_ts=True)
            cmd("ostree", "static-delta", "generate", "--repo=./ostree_repo", "--from", sha, "--to", d.to[0])
            prog.tick()

    # update summary and generate a new type of delta indexes
    cmd("ostree", "summary", "-u", "--repo=./ostree_repo")

    # TODO: remove the following code that determines and prints a type of delta indexes been generated
    #  once we completely switch to the new indexes types. https://foundriesio.atlassian.net/browse/FFTK-1122
    if os.path.isdir("./ostree_repo/delta-indexes"):
        with open("./ostree_repo/config", "r") as f:
            config = f.readlines()
        for e in config:
            if e == "indexed-deltas=true\n":
                status("New type of delta indexes are generated and enabled in the repo config")
                break
    else:
        status("Old type of delta indexes are generated (in-summary type)")

    rmtree("./ostree_repo/objects")  # We just need to sync deltas
    os.remove("./ostree_repo/summary")  # summary is generated by the ostree server
    cmd("fiopush", "-summary", "-repo=./ostree_repo", "-creds", creds_zip_file)
    prog.tick()


if __name__ == "__main__":
    require_secrets("osftok", "triggered-by", "deltas", "targets.sec", 'root.json', 'targets.pub')
    _, creds_tmp = mkstemp()
    generate_credential_tokens(creds_tmp)

    deltas: List[Delta] = []
    for d in json.loads(secret("deltas")):
        deltas.append(Delta(**d))

    repo_parent = os.environ.get("OSTREE_REPO_ROOT", "/")
    os.chdir(repo_parent)
    main(creds_tmp, deltas)
